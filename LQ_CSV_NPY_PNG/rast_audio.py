import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms, models
from torchvision.utils import make_grid  # <--- [ì¶”ê°€ë¨] ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í•¨ìˆ˜
import wandb
from tqdm import tqdm
import random

# ============================================================
# 0. ìµœì¢… í•™ìŠµ ì„¤ì • (Final Hyperparameters)
# ============================================================
CONFIG = {
    "project_name": "audio-deepfake-final-training",  # ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ì´ë¦„
    "run_name": "efficientnet_b0_final_run",          # ì´ë²ˆ í•™ìŠµì˜ ì´ë¦„
    
    # --- ë°ì´í„° ë° ëª¨ë¸ ì„¤ì • ---
    "data_dir": "./3_audio_spectrograms",
    "image_size": 128,
    "silence_threshold": 10,
    "model_name": "efficientnet_b0",
    "latent_dim": 256,           # Phase 1 ìµœì ê°’
    
    # --- í•™ìŠµ íŒŒë¼ë¯¸í„° ---
    "batch_size": 16,            # Phase 1 ìµœì ê°’
    "num_epochs": 100,           # ìš”ì²­ì‚¬í•­: 100 ì—í¬í¬ë¡œ ì¦ê°€
    "learning_rate": 0.0005,     # ìš”ì²­ì‚¬í•­: ê¸°ì¡´(0.0039)ë³´ë‹¤ ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ì •ë°€ í•™ìŠµ ìœ ë„
    "optimizer": "adamw",        # Phase 1 ìµœì ê°’
    "weight_decay": 1.28e-4,     # Phase 1 ìµœì ê°’ (0.000128...)
    
    # --- ì‹œìŠ¤í…œ ì„¤ì • ---
    "num_workers": 4,
    "seed": 42
}

# ============================================================
# 1. ìœ í‹¸ë¦¬í‹°: ì‹œë“œ ê³ ì • ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
# ============================================================
def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"ğŸŒ± Seed set to {seed}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ============================================================
# 2. Dataset Class
# ============================================================
class MelSpectrogramDataset(Dataset):
    def __init__(self, data_dir, transform=None, silence_threshold=10):
        self.data_dir = data_dir
        self.transform = transform
        self.silence_threshold = silence_threshold
        
        self.image_paths = []
        # ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(data_dir):
            raise FileNotFoundError(f"âŒ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")

        for fname in os.listdir(data_dir):
            if fname.endswith('.png'):
                fpath = os.path.join(data_dir, fname)
                if not self._is_silence(fpath):
                    self.image_paths.append(fpath)
        
        print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: ì´ {len(self.image_paths)}ì¥ (ì œì™¸ëœ ì¹¨ë¬µ ë°ì´í„° í¬í•¨)")
    
    def _is_silence(self, img_path):
        img = cv2.imread(img_path)
        if img is None: return True
        mean_intensity = np.mean(img)
        return mean_intensity < self.silence_threshold
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGR -> RGB
        
        if self.transform:
            image = self.transform(image)
        
        return image

# ============================================================
# 3. Model Architecture: EfficientNet-B0 Autoencoder
# ============================================================
class EfficientNetAutoencoder(nn.Module):
    def __init__(self, latent_dim=256):
        super().__init__()
        
        # --- Encoder (Pre-trained EfficientNet-B0) ---
        print(f"ğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘: EfficientNet-B0 (Latent Dim: {latent_dim})")
        # weights íŒŒë¼ë¯¸í„° ê²½ê³ ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ìµœì‹  ë°©ì‹ ê¶Œì¥ë˜ì§€ë§Œ, 
        # í˜¸í™˜ì„±ì„ ìœ„í•´ pretrained=True ìœ ì§€ (ê²½ê³ ëŠ” ë¬´ì‹œí•´ë„ í•™ìŠµì—” ì§€ì¥ ì—†ìŒ)
        efficientnet = models.efficientnet_b0(pretrained=True)
        
        # EfficientNetì˜ íŠ¹ì§• ì¶”ì¶œê¸° ë¶€ë¶„ë§Œ ì‚¬ìš©
        self.encoder_features = efficientnet.features
        
        # Flatten ë° Latent Vector ìƒì„±
        self.encoder_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(1280, latent_dim), # EfficientNet-B0ì˜ ë§ˆì§€ë§‰ ì±„ë„ì€ 1280
            nn.ReLU()
        )
        
        # --- Decoder ---
        # Latent Vectorë¥¼ ë‹¤ì‹œ ê³µê°„ì  íŠ¹ì§•ë§µìœ¼ë¡œ í™•ì¥
        self.decoder_input = nn.Linear(latent_dim, 1280 * 4 * 4)
        
        self.decoder_layers = nn.Sequential(
            nn.ReLU(),
            nn.Unflatten(1, (1280, 4, 4)), # (Batch, 1280, 4, 4)
            
            # 4x4 -> 8x8
            nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            
            # 8x8 -> 16x16
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            
            # 16x16 -> 32x32
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            # 32x32 -> 64x64
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            # 64x64 -> 128x128 (Output Size)
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid() # í”½ì…€ ê°’ì„ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™” (ì´ë¯¸ì§€ ë³µì›)
        )
    
    def forward(self, x):
        # Encode
        x = self.encoder_features(x)
        latent = self.encoder_head(x)
        
        # Decode
        x = self.decoder_input(latent)
        reconstructed = self.decoder_layers(x)
        
        return reconstructed

# ============================================================
# 4. Training Loop (Final)
# ============================================================
def train_final_model():
    # 1. ì‹œë“œ ì„¤ì •
    set_seed(CONFIG['seed'])
    
    # 2. WandB ì´ˆê¸°í™”
    wandb.init(
        project=CONFIG['project_name'],
        name=CONFIG['run_name'],
        config=CONFIG,
        reinit=True
    )
    config = wandb.config
    
    # 3. ë°ì´í„° ë¡œë“œ
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((config.image_size, config.image_size)),
        transforms.ToTensor(), # 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜ë¨
    ])
    
    full_dataset = MelSpectrogramDataset(
        data_dir=config.data_dir,
        transform=transform,
        silence_threshold=config.silence_threshold
    )
    
    # Train/Val ë¶„í•  (9:1)
    train_size = int(0.9 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)
    
    print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
    
    # 4. ëª¨ë¸ ë° í•™ìŠµ ë„êµ¬ ì„¤ì •
    model = EfficientNetAutoencoder(latent_dim=config.latent_dim).to(device)
    
    criterion = nn.MSELoss() # ë³µì› ì˜¤ì°¨ (Mean Squared Error)
    
    # Optimizer: AdamW ì‚¬ìš© (Phase 1 ìµœì  ê²°ê³¼)
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=config.learning_rate, 
        weight_decay=config.weight_decay
    )
    
    # Scheduler: verbose=True ì œê±° (ì´ì „ ì—ëŸ¬ ìˆ˜ì •ë¨)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10
    )
    
    # WandBì— ëª¨ë¸ êµ¬ì¡° ì¶”ì 
    wandb.watch(model, log='all', log_freq=100)
    
    best_val_loss = float('inf')
    
    # 5. í•™ìŠµ ë£¨í”„ ì‹œì‘
    print("\nğŸš€ ìµœì¢… í•™ìŠµ ì‹œì‘ (100 Epochs)...")
    
    for epoch in range(config.num_epochs):
        start_time = torch.cuda.Event(enable_timing=True)
        end_time = torch.cuda.Event(enable_timing=True)
        start_time.record()
        
        # --- Training Phase ---
        model.train()
        train_loss = 0.0
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.num_epochs} [Train]")
        for images in train_pbar:
            images = images.to(device)
            
            # Forward
            reconstructed = model(images)
            loss = criterion(reconstructed, images)
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            train_pbar.set_postfix({'loss': f"{loss.item():.6f}"})
            
        avg_train_loss = train_loss / len(train_loader)
        
        # --- Validation Phase ---
        model.eval()
        val_loss = 0.0
        sample_images = None # ì´ˆê¸°í™”
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{config.num_epochs} [Val]")
            for i, images in enumerate(val_pbar):
                images = images.to(device)
                reconstructed = model(images)
                loss = criterion(reconstructed, images)
                val_loss += loss.item()
                val_pbar.set_postfix({'loss': f"{loss.item():.6f}"})
                
                # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« 4ì¥ ì´ë¯¸ì§€ë§Œ ì €ì¥ (ì‹œê°í™”ìš©)
                if i == 0:
                    # Tensor -> Numpy ë³€í™˜ ë° ì‹œê°í™” ì¤€ë¹„
                    orig = images[:4].cpu()
                    recon = reconstructed[:4].cpu()
                    
                    # dim=2(Height)ë¡œ ë¶™ì˜€ìœ¼ë¯€ë¡œ (B, C, H*2, W) í˜•íƒœê°€ ë¨.
                    # ì¦‰, ìœ„(ì›ë³¸), ì•„ë˜(ë³µì›) í˜•íƒœì˜ ì„¸ë¡œë¡œ ê¸´ ì´ë¯¸ì§€ë“¤ì´ ë°°ì¹˜ë¡œ ë¬¶ì„.
                    comparison = torch.cat([orig, recon], dim=2) 
                    sample_images = comparison
        
        avg_val_loss = val_loss / len(val_loader)
        
        # --- Logging & Saving ---
        current_lr = optimizer.param_groups[0]['lr']
        
        log_dict = {
            "epoch": epoch + 1,
            "train_loss": avg_train_loss,
            "val_loss": avg_val_loss,
            "learning_rate": current_lr
        }
        
        # 10 ì—í¬í¬ë§ˆë‹¤ ì´ë¯¸ì§€ ì‹œê°í™” ë¡œê¹… (ì›ë³¸ vs ë³µì›)
        # sample_imagesê°€ Noneì´ ì•„ë‹ ë•Œë§Œ ë¡œê¹…
        if sample_images is not None and ((epoch + 1) % 10 == 0 or (epoch + 1) == 1):
            # [ìˆ˜ì •ë¨] 4D Tensor (Batch, C, H, W) -> 3D Grid Image (C, H_grid, W_grid)
            # nrow=4ë¡œ ì„¤ì •í•˜ì—¬ 4ê°œë¥¼ ê°€ë¡œë¡œ ë‚˜ì—´
            grid_tensor = make_grid(sample_images, nrow=4, padding=2)
            
            grid_image = wandb.Image(
                grid_tensor, 
                caption=f"Epoch {epoch+1}: Top(Original) / Bottom(Reconstructed)"
            )
            log_dict["Reconstruction_Vis"] = grid_image
            
        wandb.log(log_dict)
        
        # Scheduler Update
        scheduler.step(avg_val_loss)
        
        # Best Model ì €ì¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), "best_model_final.pth")
            wandb.save("best_model_final.pth") # WandB í´ë¼ìš°ë“œì—ë„ ì—…ë¡œë“œ
            print(f"â­ New Best Model Saved! (Val Loss: {best_val_loss:.6f})")
            
        end_time.record()
        torch.cuda.synchronize()
        elapsed_time = start_time.elapsed_time(end_time) / 1000 # ì´ˆ ë‹¨ìœ„
        print(f"   -> Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}, Time: {elapsed_time:.1f}s")

    # 6. í•™ìŠµ ì¢…ë£Œ ë° ìµœì¢… ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), "final_model_100ep.pth")
    wandb.save("final_model_100ep.pth")
    
    print("="*60)
    print(f"ğŸ‰ ëª¨ë“  í•™ìŠµ ì™„ë£Œ! ìµœì¢… Val Loss: {avg_val_loss:.6f}")
    print(f"ğŸ† Best Val Loss: {best_val_loss:.6f}")
    print("="*60)
    
    wandb.finish()

# ============================================================
# Main Execution
# ============================================================
if __name__ == "__main__":
    # í•„ìš”í•œ í´ë” ìƒì„± ë° ì²´í¬
    if not os.path.exists(CONFIG['data_dir']):
        print(f"âŒ ê²½ê³ : '{CONFIG['data_dir']}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        train_final_model()