"""ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ì˜ìƒ ìƒì„± ì„œë¹„ìŠ¤.

MediaPipeë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì—ì„œ ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ê³ ,
ëœë“œë§ˆí¬ê°€ ê·¸ë ¤ì§„ ìƒˆë¡œìš´ ì˜ìƒì„ ìƒì„±í•œë‹¤.
"""

import cv2
import mediapipe as mp
import numpy as np
from pathlib import Path
from typing import Optional
import time


class LandmarkExtractor:
    """ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì˜ìƒ ìƒì„± í´ë˜ìŠ¤."""
    
    def __init__(self):
        """MediaPipe Face Mesh ì´ˆê¸°í™”."""
        self.mp_face_mesh = mp.solutions.face_mesh
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # Face Mesh ì„¤ì • (ì •ì  ì´ë¯¸ì§€ ëª¨ë“œ êº¼ì„œ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìµœì í™”)
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=False,
            max_num_faces=1,  # í•œ ì–¼êµ´ë§Œ ì²˜ë¦¬ (ì†ë„ í–¥ìƒ)
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
    
    def extract_landmarks_from_video(
        self, 
        input_path: str, 
        output_path: str,
        max_processing_time: Optional[float] = None,
        target_fps: Optional[int] = None
    ) -> dict:
        """ì˜ìƒì—ì„œ ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì˜ìƒìœ¼ë¡œ ì €ì¥.
        
        Args:
            input_path: ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
            max_processing_time: ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ) - ì´ ì‹œê°„ ì´ˆê³¼ ì‹œ ì¤‘ë‹¨
            target_fps: ì¶œë ¥ ì˜ìƒì˜ FPS (Noneì´ë©´ ì›ë³¸ê³¼ ë™ì¼)
        
        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
                - success: ì„±ê³µ ì—¬ë¶€
                - processed_frames: ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜
                - total_frames: ì „ì²´ í”„ë ˆì„ ìˆ˜
                - processing_time: ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
                - output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
                - faces_detected: ì–¼êµ´ì´ ê°ì§€ëœ í”„ë ˆì„ ìˆ˜
        """
        start_time = time.time()
        
        # ì…ë ¥ ì˜ìƒ ì—´ê¸°
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            return {
                "success": False,
                "error": "Failed to open video file"
            }
        
        # ì˜ìƒ ì†ì„± ê°€ì ¸ì˜¤ê¸°
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # ì¶œë ¥ FPS ì„¤ì • (ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ)
        output_fps = target_fps if target_fps else fps
        
        # VideoWriter ì„¤ì • - H.264 ì½”ë± ì‚¬ìš© (ë¸Œë¼ìš°ì € í˜¸í™˜)
        # x264 ì½”ë±ì„ ì‚¬ìš©í•˜ë©´ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒ ê°€ëŠ¥
        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264
        out = cv2.VideoWriter(output_path, fourcc, output_fps, (width, height))
        
        # avc1ì´ ì•ˆ ë˜ë©´ mp4vë¡œ í´ë°±
        if not out.isOpened():
            print("âš ï¸  avc1 ì½”ë± ì‹¤íŒ¨, mp4vë¡œ ì¬ì‹œë„...")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, output_fps, (width, height))
        
        if not out.isOpened():
            cap.release()
            return {
                "success": False,
                "error": "Failed to create output video file"
            }
        
        processed_frames = 0
        faces_detected = 0
        
        try:
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ì‹œê°„ ì œí•œ ì²´í¬ (ì§€ì •ëœ ì‹œê°„ ì´ˆê³¼ ì‹œ ì¤‘ë‹¨)
                if max_processing_time and (time.time() - start_time) > max_processing_time:
                    print(f"â±ï¸  ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„({max_processing_time}ì´ˆ) ë„ë‹¬. ì²˜ë¦¬ ì¤‘ë‹¨.")
                    break
                
                # RGBë¡œ ë³€í™˜ (MediaPipeëŠ” RGB ì‚¬ìš©)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
                results = self.face_mesh.process(rgb_frame)
                
                # ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ë©´ ê·¸ë¦¬ê¸°
                if results.multi_face_landmarks:
                    faces_detected += 1
                    for face_landmarks in results.multi_face_landmarks:
                        # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                        self.mp_drawing.draw_landmarks(
                            image=frame,
                            landmark_list=face_landmarks,
                            connections=self.mp_face_mesh.FACEMESH_TESSELATION,
                            landmark_drawing_spec=None,
                            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_tesselation_style()
                        )
                        
                        # ìœ¤ê³½ì„  ê°•ì¡°
                        self.mp_drawing.draw_landmarks(
                            image=frame,
                            landmark_list=face_landmarks,
                            connections=self.mp_face_mesh.FACEMESH_CONTOURS,
                            landmark_drawing_spec=None,
                            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_contours_style()
                        )
                        
                        # ëˆˆë™ì ê°•ì¡°
                        self.mp_drawing.draw_landmarks(
                            image=frame,
                            landmark_list=face_landmarks,
                            connections=self.mp_face_mesh.FACEMESH_IRISES,
                            landmark_drawing_spec=None,
                            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_iris_connections_style()
                        )
                
                # í”„ë ˆì„ ì €ì¥
                out.write(frame)
                processed_frames += 1
                
        finally:
            cap.release()
            out.release()
        
        processing_time = time.time() - start_time
        
        # ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•´ ffmpegë¡œ ì¬ì¸ì½”ë”©
        try:
            import subprocess
            import platform
            from app.core.config import settings
            
            temp_output = output_path + ".temp.mp4"
            
            # ì›ë³¸ì„ tempë¡œ ì´ë™
            Path(output_path).rename(temp_output)
            
            # ffmpeg ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            ffmpeg_cmd = 'ffmpeg'
            
            # ì„¤ì • íŒŒì¼ì— ê²½ë¡œê°€ ì§€ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
            if settings.FFMPEG_PATH:
                ffmpeg_cmd = settings.FFMPEG_PATH
                print(f"ğŸ“ ì„¤ì •ëœ ffmpeg ê²½ë¡œ ì‚¬ìš©: {ffmpeg_cmd}")
            # Windowsì—ì„œ ffmpegê°€ PATHì— ì—†ì„ ê²½ìš° ì§ì ‘ ê²½ë¡œ ì§€ì •
            elif platform.system() == 'Windows':
                # ì¼ë°˜ì ì¸ ì„¤ì¹˜ ê²½ë¡œë“¤ ì²´í¬
                possible_paths = [
                    'ffmpeg',  # PATHì— ìˆëŠ” ê²½ìš°
                    r'C:\ffmpeg\bin\ffmpeg.exe',
                    r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
                    r'C:\ëŒ€í•™êµ í´ë”\í”„ë¡œì íŠ¸ ì‘ìš©\ë”¥í˜ì´í¬\ffmpeg-8.0-full_build\bin\ffmpeg.exe',
                ]
                
                for path in possible_paths:
                    try:
                        result = subprocess.run([path, '-version'], 
                                              capture_output=True, 
                                              timeout=5)
                        if result.returncode == 0:
                            ffmpeg_cmd = path
                            print(f"âœ… ffmpeg ë°œê²¬: {path}")
                            break
                    except:
                        continue
            
            # ffmpegë¡œ H.264 ì¬ì¸ì½”ë”©
            ffmpeg_full_cmd = [
                ffmpeg_cmd,
                '-i', temp_output,
                '-c:v', 'libx264',
                '-preset', 'ultrafast',
                '-crf', '23',
                '-pix_fmt', 'yuv420p',
                '-movflags', '+faststart',
                '-y',
                output_path
            ]
            
            result = subprocess.run(
                ffmpeg_full_cmd,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # ì„±ê³µ - temp íŒŒì¼ ì‚­ì œ
                Path(temp_output).unlink()
                print("âœ… ffmpeg ì¬ì¸ì½”ë”© ì™„ë£Œ (ë¸Œë¼ìš°ì € í˜¸í™˜)")
            else:
                # ì‹¤íŒ¨ - tempë¥¼ ì›ë³¸ìœ¼ë¡œ ë³µì›
                print(f"âš ï¸  ffmpeg ì¬ì¸ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {result.stderr}")
                Path(temp_output).rename(output_path)
        except Exception as e:
            print(f"âš ï¸  ffmpeg í›„ì²˜ë¦¬ ì‹¤íŒ¨ (ffmpeg ë¯¸ì„¤ì¹˜?): {e}")
            # temp íŒŒì¼ì´ ìˆìœ¼ë©´ ì›ë³¸ìœ¼ë¡œ ë³µì›
            temp_path = Path(output_path + ".temp.mp4")
            if temp_path.exists():
                temp_path.rename(output_path)
        
        return {
            "success": True,
            "processed_frames": processed_frames,
            "total_frames": total_frames,
            "processing_time": round(processing_time, 2),
            "output_path": output_path,
            "faces_detected": faces_detected,
            "fps": output_fps,
            "resolution": f"{width}x{height}"
        }
    
    def __del__(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬."""
        if hasattr(self, 'face_mesh'):
            self.face_mesh.close()


def create_landmark_video(
    input_path: str,
    output_dir: str = "uploads/landmarks",
    max_processing_time: float = 3.0
) -> dict:
    """ì˜ìƒì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜.
    
    Args:
        input_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        max_processing_time: ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
    
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    input_file = Path(input_path)
    output_filename = f"landmark_{input_file.stem}{input_file.suffix}"
    output_file = output_path / output_filename
    
    # ëœë“œë§ˆí¬ ì¶”ì¶œ (ì‹œê°„ ì œí•œë§Œ ì ìš©)
    extractor = LandmarkExtractor()
    result = extractor.extract_landmarks_from_video(
        input_path=input_path,
        output_path=str(output_file),
        max_processing_time=max_processing_time
    )
    
    if result["success"]:
        result["output_filename"] = output_filename
    
    return result


# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš© ë©”ì¸
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python landmark_extractor.py <video_path>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    result = create_landmark_video(video_path)
    
    if result["success"]:
        print(f"âœ… ëœë“œë§ˆí¬ ì˜ìƒ ìƒì„± ì™„ë£Œ!")
        print(f"   - ì¶œë ¥ íŒŒì¼: {result['output_path']}")
        print(f"   - ì²˜ë¦¬ í”„ë ˆì„: {result['processed_frames']}/{result['total_frames']}")
        print(f"   - ì–¼êµ´ ê°ì§€: {result['faces_detected']}í”„ë ˆì„")
        print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']}ì´ˆ")
    else:
        print(f"âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
