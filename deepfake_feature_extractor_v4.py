import cv2
import dlib
import numpy as np
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
import moviepy.editor as mp # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
import os
import time
from scipy.spatial import distance as dist

# ============================================================
# 1. ì‚¬ìš©ì ì„¤ì • (í•„ìˆ˜)
# ============================================================
DLIB_PREDICTOR_PATH = "shape_predictor_68_face_landmarks.dat"
VIDEO_SOURCE_DIR = "../test" # âš ï¸ [ìˆ˜ì •í•„ìš”] ì›ë³¸ ë¹„ë””ì˜¤ í´ë”ã„´
OUTPUT_DIR = "../output"       # âš ï¸ [ìˆ˜ì •í•„ìš”] ê²°ê³¼ë¬¼ ì €ì¥ í´ë”

VAD_TARGET_DURATION = 3.0 # ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì¡°ê°ì˜ ê¸¸ì´ (ì´ˆ)
VAD_SR = 22050 # VAD ë¶„ì„ì„ ìœ„í•œ ìƒ˜í”Œë§ ì†ë„ (ë¹ ë¦„)A
VAD_TOP_DB = 40 # ì¹¨ë¬µì„ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ (dB)

# ============================================================
# 2. ì¶œë ¥ í´ë” ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •
# ============================================================
CSV_OUTPUT_PATH = os.path.join(OUTPUT_DIR, "1_statistics_all_summary.csv")  
NPY_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "2_npy_timeseries")
AUDIO_IMG_DIR = os.path.join(OUTPUT_DIR, "3_audio_spectrograms")

# ============================================================
# 3. dlib ëª¨ë¸ ë¡œë“œ (CPUìš© HOG)
# ============================================================
try:
    print("dlib CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: False (CPU HOG íƒì§€ê¸° ëª¨ë“œ)")
    print("CPUìš© dlib HOG ì–¼êµ´ íƒì§€ê¸° ë¡œë“œ ì¤‘...")
    detector = dlib.get_frontal_face_detector()
    print("âœ“ HOG íƒì§€ê¸° ë¡œë“œ ì™„ë£Œ.")
    
    print(f"ì–¼êµ´ ëœë“œë§ˆí¬ ì˜ˆì¸¡ê¸° ë¡œë“œ ì¤‘ ({DLIB_PREDICTOR_PATH})...")
    predictor = dlib.shape_predictor(DLIB_PREDICTOR_PATH)
    print("âœ“ ëœë“œë§ˆí¬ ì˜ˆì¸¡ê¸° ë¡œë“œ ì™„ë£Œ.")
    
except Exception as e:
    print(f"âŒ dlib ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print(f"'{DLIB_PREDICTOR_PATH}' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# ============================================================
# 4. ì–¼êµ´ ì˜ì—­ë³„ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ ì •ì˜
# ============================================================
FACIAL_LANDMARKS = {
    "left_eye": list(range(36, 42)),
    "right_eye": list(range(42, 48)),
    "nose": list(range(27, 36)),
    "mouth": list(range(48, 68)),
    "jawline": list(range(0, 17)),
    "full_face": list(range(0, 68))
}

# ============================================================
# 5. í—¬í¼ í•¨ìˆ˜ ì •ì˜
# ============================================================

def get_region_bounding_box(shape, landmark_indices):
    points = [(shape.part(i).x, shape.part(i).y) for i in landmark_indices]
    xs, ys = zip(*points)
    return (min(xs), min(ys), max(xs), max(ys))


def calculate_region_features(gray_frame, shape, region_name, landmark_indices, 
                               prev_region_mean=None):
    try:
        x_min, y_min, x_max, y_max = get_region_bounding_box(shape, landmark_indices)
        h, w = gray_frame.shape
        x_min, y_min = max(0, x_min), max(0, y_min)
        x_max, y_max = min(w, x_max), min(h, y_max)
        
        region_crop = gray_frame[y_min:y_max, x_min:x_max]
        
        if region_crop.size == 0:
            return None
        
        laplacian = cv2.Laplacian(region_crop, cv2.CV_64F)
        laplacian_mean = np.abs(laplacian).mean()
        laplacian_var = laplacian.var()
        light_intensity_mean = region_crop.mean()
        
        light_intensity_change = 0.0
        if prev_region_mean is not None:
            light_intensity_change = light_intensity_mean - prev_region_mean
        
        region_area = (x_max - x_min) * (y_max - y_min)
        
        return {
            'laplacian_mean': laplacian_mean,
            'laplacian_var': laplacian_var,
            'light_intensity_mean': light_intensity_mean,
            'light_intensity_change': light_intensity_change,
            'region_area': region_area
        }
    except Exception as e:
        print(f"      âš ï¸ {region_name} ì˜ì—­ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


def save_mel_spectrogram(audio_segment, sr, file_path):
    try:
        S = librosa.feature.melspectrogram(y=audio_segment, sr=sr, n_mels=128)
        S_dB = librosa.power_to_db(S, ref=np.max)
        
        plt.figure(figsize=(10, 4))
        librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')
        plt.axis('off')
        plt.savefig(file_path, dpi=100, bbox_inches='tight', pad_inches=0)
        plt.close()
    except Exception as e:
        print(f"    âš ï¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì €ì¥ ì‹¤íŒ¨: {e}")


# ============================================================
# 6. ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================
def process_video_segment(video_path, segment_name, start_sec, end_sec, base_output_name):
    print(f"  â³ '{segment_name}' ì„¸ê·¸ë¨¼íŠ¸ ({start_sec:.2f}s - {end_sec:.2f}s) ì²˜ë¦¬ ì‹œì‘...")
    
    # --- PART A: ë¹„ë””ì˜¤(ì˜ìƒ) ì²˜ë¦¬ ---
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"    âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        return None

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0:
        print(f"    âŒ FPSê°€ 0ì…ë‹ˆë‹¤. íŒŒì¼ ì†ìƒ ê°€ëŠ¥ì„±")
        cap.release()
        return None
        
    start_frame = int(start_sec * fps)
    end_frame = int(end_sec * fps)
    
    # [ìˆ˜ì •] OpenCVê°€ ê¸´ ì˜ìƒì˜ ë¨¼ ê³³ìœ¼ë¡œ seek í•˜ëŠ” ë° ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
    # set() í•¨ìˆ˜ê°€ ì œëŒ€ë¡œ ì‘ë™í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§ ì¶”ê°€
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    # í˜„ì¬ ìœ„ì¹˜ë¥¼ ë‹¤ì‹œ ì½ì–´ì™€ì„œ, ì„¤ì •í•œ start_frameê³¼ 1í”„ë ˆì„ ì´ìƒ ì°¨ì´ë‚˜ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
    actual_start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)
    if abs(actual_start_frame - start_frame) > 1:
        print(f"    âŒ OpenCV ë¹„ë””ì˜¤ íƒìƒ‰(seek) ì‹¤íŒ¨. (ìš”ì²­: {start_frame}, ì‹¤ì œ: {actual_start_frame})")
        cap.release()
        # moviepyë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ í´ë¦½ ì˜ë¼ë‚´ê¸°ë¥¼ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆìœ¼ë‚˜, ì¼ë‹¨ ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
        return None
        
    frame_data = { 'frame_number': [], 'timestamp_sec': [] }
    for region_name in FACIAL_LANDMARKS.keys():
        frame_data[f'{region_name}_laplacian_mean'] = []
        frame_data[f'{region_name}_laplacian_var'] = []
        frame_data[f'{region_name}_light_intensity_mean'] = []
        frame_data[f'{region_name}_light_intensity_change'] = []
        frame_data[f'{region_name}_area'] = []
    
    prev_light_means = {region: None for region in FACIAL_LANDMARKS.keys()}
    processed_frames = 0
    
    # [ìˆ˜ì •] end_frame ëŒ€ì‹  (end_frame - start_frame) ë§Œí¼ ì½ë„ë¡ ë³€ê²½
    frames_to_read = end_frame - start_frame
    for i in range(frames_to_read):
        ret, frame = cap.read()
        if not ret:
            break
        
        current_frame_num = start_frame + i
        
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = detector(gray) 
            if len(faces) == 0: continue
            
            face = faces[0] 
            shape = predictor(gray, face)
            
            frame_data['frame_number'].append(current_frame_num)
            frame_data['timestamp_sec'].append(current_frame_num / fps)
            
            for region_name, landmark_indices in FACIAL_LANDMARKS.items():
                features = calculate_region_features(
                    gray, shape, region_name, landmark_indices,
                    prev_region_mean=prev_light_means[region_name]
                )
                if features:
                    frame_data[f'{region_name}_laplacian_mean'].append(features['laplacian_mean'])
                    frame_data[f'{region_name}_laplacian_var'].append(features['laplacian_var'])
                    frame_data[f'{region_name}_light_intensity_mean'].append(features['light_intensity_mean'])
                    frame_data[f'{region_name}_light_intensity_change'].append(features['light_intensity_change'])
                    frame_data[f'{region_name}_area'].append(features['region_area'])
                    prev_light_means[region_name] = features['light_intensity_mean']
                else:
                    [frame_data[f'{region_name}_{ftype}'].append(np.nan) for ftype in ['laplacian_mean', 'laplacian_var', 'light_intensity_mean', 'light_intensity_change', 'area']]
            
            processed_frames += 1
            
        except Exception as e:
            print(f"      âš ï¸ í”„ë ˆì„ {current_frame_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    cap.release()
    if processed_frames == 0:
        print(f"    âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ (ì²˜ë¦¬ëœ í”„ë ˆì„: 0)")
        return None
    print(f"    âœ“ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {processed_frames} í”„ë ˆì„")
    
    # --- PART B: í†µê³„ ë°ì´í„° ìƒì„± ---
    df_frames = pd.DataFrame(frame_data)
    stats_data = {'video_id': base_output_name, 'segment': segment_name}
    for region_name in FACIAL_LANDMARKS.keys():
        for feature_type in ['laplacian_mean', 'laplacian_var', 'light_intensity_mean', 
                             'light_intensity_change', 'area']:
            col_name = f'{region_name}_{feature_type}'
            if col_name in df_frames.columns:
                series = df_frames[col_name].dropna()
                if not series.empty:
                    stats_data[f'{col_name}_avg'] = series.mean()
                    stats_data[f'{col_name}_std'] = series.std()
                    stats_data[f'{col_name}_max'] = series.max()
                    stats_data[f'{col_name}_min'] = series.min()
                else:
                    stats_data.update({f'{col_name}_avg': 0, f'{col_name}_std': 0, f'{col_name}_max': 0, f'{col_name}_min': 0})
    
    # --- PART C: NPY íŒŒì¼ ìƒì„± (ìƒì„¸í•œ ì‹œê³„ì—´ ë°ì´í„°) ---
    npy_data = {
        'frame_numbers': np.array(frame_data['frame_number']),
        'timestamps': np.array(frame_data['timestamp_sec']),
        'video_id': base_output_name,
        'segment': segment_name,
        'fps': fps,
        'total_frames': processed_frames
    }
    for region_name in FACIAL_LANDMARKS.keys():
        npy_data[region_name] = {
            'laplacian_mean': np.array(frame_data[f'{region_name}_laplacian_mean']),
            'laplacian_var': np.array(frame_data[f'{region_name}_laplacian_var']),
            'light_intensity_mean': np.array(frame_data[f'{region_name}_light_intensity_mean']),
            'light_intensity_change': np.array(frame_data[f'{region_name}_light_intensity_change']),
            'area': np.array(frame_data[f'{region_name}_area'])
        }
    npy_path = os.path.join(NPY_OUTPUT_DIR, f"{base_output_name}.npy")
    np.save(npy_path, npy_data, allow_pickle=True)
    print(f"    âœ“ NPY ì €ì¥ ì™„ë£Œ: {npy_path}")
    
    # --- PART D: ì˜¤ë””ì˜¤ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ ìƒì„± (v8ê³¼ ë™ì¼) ---
    try:
        target_sr = 44100 
        duration = end_sec - start_sec
        
        y, sr = librosa.load(
            video_path, 
            sr=target_sr, 
            offset=start_sec, 
            duration=duration
        )
        
        if y.size == 0:
            print(f"    âš ï¸ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ë¹„ì–´ìˆìŒ (librosa)")
        else:
            audio_img_path = os.path.join(AUDIO_IMG_DIR, f"{base_output_name}.png")
            save_mel_spectrogram(y, sr, audio_img_path)
            print(f"    âœ“ ì˜¤ë””ì˜¤ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {audio_img_path}")
            
    except Exception as e:
        print(f"    âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ (librosa): {e}")
    
    return stats_data

# ============================================================
# 8. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (VAD ë²„ê·¸ ìˆ˜ì •ë¨)
# ============================================================

def main():
    start_time = time.time()
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(NPY_OUTPUT_DIR, exist_ok=True)
    os.makedirs(AUDIO_IMG_DIR, exist_ok=True)
    
    print("="*70)
    print("ğŸ¬ ë”¥í˜ì´í¬ ê°ì§€ìš© ë©€í‹°ëª¨ë‹¬ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ (v10 - CPU HOG / VAD ë²„ê·¸ ìˆ˜ì •)")
    print("="*70)
    print(f"ğŸ“‚ ë¹„ë””ì˜¤ ì†ŒìŠ¤: {VIDEO_SOURCE_DIR}")
    print(f"ğŸ“‚ ì¶œë ¥ í´ë”: {OUTPUT_DIR}")
    print(f"ğŸ¤ VAD (ìŒì„± ê°ì§€) ê¸°ì¤€: {VAD_TOP_DB}dB, {VAD_TARGET_DURATION}ì´ˆ")
    print("="*70)
    
    video_files = []
    for root, _, files in os.walk(VIDEO_SOURCE_DIR):
        for file in files:
            if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
                video_files.append(os.path.join(root, file))
    
    if not video_files:
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_SOURCE_DIR}")
        return
    
    print(f"\nğŸ” ë°œê²¬ëœ ë¹„ë””ì˜¤: {len(video_files)}ê°œ\n")
    
    # ì´ì–´í•˜ê¸° ê¸°ëŠ¥ ë¡œì§
    all_new_stats = [] 
    processed_video_ids = set()
    file_exists = os.path.exists(CSV_OUTPUT_PATH)

    if file_exists:
        print(f"ğŸ”„ ê¸°ì¡´ í†µê³„ íŒŒì¼ {CSV_OUTPUT_PATH}ì„(ë¥¼) ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. (ì´ì–´í•˜ê¸°)")
        try:
            df_existing = pd.read_csv(CSV_OUTPUT_PATH)
            processed_video_ids = set(df_existing['video_id'])
            print(f"   ({len(processed_video_ids)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì´ë¯¸ ì²˜ë¦¬ë¨)")
        except Exception as e:
            print(f"   âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}. ìƒˆ íŒŒì¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
            file_exists = False
    
    total_segments_to_process = 0
    success_count = 0 
    fail_count = 0 
    skipped_count = 0 
    
    # ê° ë¹„ë””ì˜¤ ì²˜ë¦¬
    for i, video_path in enumerate(video_files):
        video_name = os.path.basename(video_path)
        base_name = os.path.splitext(video_name)[0]
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¹ [{i+1}/{len(video_files)}] {video_name}")
        print(f"{'='*70}")
        
        # --- VAD (Voice Activity Detection) ë¡œì§ ---
        segments_to_process = {}
        try:
            print("  ğŸ”‰ ì˜¤ë””ì˜¤ ë¶„ì„ (VAD) ì‹œì‘...")
            y_full, sr_full = librosa.load(video_path, sr=VAD_SR)
            
            # [ë²„ê·¸ ìˆ˜ì •] librosa.effects.splitì€ 'ìƒ˜í”Œ' ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜
            speech_segment_samples = librosa.effects.split(y_full, top_db=VAD_TOP_DB, hop_length=512)
            
            # [ë²„ê·¸ ìˆ˜ì •] frames_to_time ëŒ€ì‹  samples_to_time ì‚¬ìš©
            speech_segments_time = librosa.samples_to_time(speech_segment_samples, sr=sr_full)
            
            # 3ì´ˆ ì´ìƒì¸ ìŒì„± êµ¬ê°„ í•„í„°ë§
            valid_segments = []
            for start_sec, end_sec in speech_segments_time:
                if end_sec - start_sec >= VAD_TARGET_DURATION:
                    valid_segments.append((start_sec, end_sec))
            
            if not valid_segments:
                print("  âš ï¸ 3ì´ˆ ì´ìƒì˜ ìŒì„± êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ ë¹„ë””ì˜¤ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            print(f"  âœ“ {len(valid_segments)}ê°œì˜ ìœ íš¨í•œ ìŒì„± êµ¬ê°„ ë°œê²¬.")

            # 3ê°œ êµ¬ê°„ ìƒ˜í”Œë§ (ì´ˆë°˜, ì¤‘ë°˜, í›„ë°˜)
            if len(valid_segments) == 1:
                start = valid_segments[0][0]
                segments_to_process['speech_1'] = (start, start + VAD_TARGET_DURATION)
            elif len(valid_segments) == 2:
                start1 = valid_segments[0][0]
                start2 = valid_segments[-1][0] # ë§ˆì§€ë§‰ êµ¬ê°„
                segments_to_process['speech_1'] = (start1, start1 + VAD_TARGET_DURATION)
                segments_to_process['speech_2'] = (start2, start2 + VAD_TARGET_DURATION)
            else: # 3ê°œ ì´ìƒ
                early_start = valid_segments[0][0]
                mid_start = valid_segments[len(valid_segments) // 2][0]
                late_start = valid_segments[-1][0]
                segments_to_process['speech_early'] = (early_start, early_start + VAD_TARGET_DURATION)
                segments_to_process['speech_mid'] = (mid_start, mid_start + VAD_TARGET_DURATION)
                segments_to_process['speech_late'] = (late_start, late_start + VAD_TARGET_DURATION)

        except Exception as e:
            print(f"  âŒ VAD ì²˜ë¦¬ ì‹¤íŒ¨ (ì˜¤ë””ì˜¤ ë¡œë“œ ì˜¤ë¥˜ ë“±): {e}")
            continue # ë‹¤ìŒ ë¹„ë””ì˜¤ë¡œ
        
        # --- VAD ë¡œì§ ë ---

        total_segments_to_process += len(segments_to_process)
        for segment_name, (start_sec, end_sec) in segments_to_process.items():
            segment_id = f"{base_name}_{segment_name}"
            
            if segment_id in processed_video_ids:
                print(f"  â¡ï¸ '{segment_name}' (ID: {segment_id})ëŠ” ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                skipped_count += 1
                continue
            
            stats_data = process_video_segment(
                video_path=video_path,
                segment_name=segment_name,
                start_sec=start_sec,
                end_sec=end_sec,
                base_output_name=segment_id
            )
            
            if stats_data:
                all_new_stats.append(stats_data) 
                success_count += 1
            else:
                fail_count += 1
        
        # 10ê°œ ë¹„ë””ì˜¤ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        if (i + 1) % 10 == 0 and all_new_stats:
            print(f"\n... ğŸ“Š {len(all_new_stats)}ê°œ ì‹ ê·œ ë°ì´í„° ì¤‘ê°„ ì €ì¥ ì¤‘ ...")
            try:
                df_intermediate = pd.DataFrame(all_new_stats)
                df_intermediate.to_csv(CSV_OUTPUT_PATH, mode='a', header=(not file_exists), index=False)
                all_new_stats = []
                file_exists = True
                print("    âœ“ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"    âŒ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")

    
    # ìµœì¢… ì €ì¥
    if all_new_stats:
        print(f"\n... ğŸ“Š {len(all_new_stats)}ê°œ ìµœì¢… ë°ì´í„° ì €ì¥ ì¤‘ ...")
        try:
            df_final = pd.DataFrame(all_new_stats)
            df_final.to_csv(CSV_OUTPUT_PATH, mode='a', header=(not file_exists), index=False)
            print("    âœ“ ìµœì¢… ì €ì¥ ì™„ë£Œ.")
        except Exception as e:
            print(f"    âŒ ìµœì¢… ì €ì¥ ì‹¤íŒ¨: {e}")

    
    elapsed_time = time.time() - start_time
    print("\n" + "="*70)
    print("ğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*70)
    print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.2f}ë¶„)")
    print(f"âœ… ìƒˆë¡œ ì„±ê³µ: {success_count} ì„¸ê·¸ë¨¼íŠ¸")
    print(f"âŒ ìƒˆë¡œ ì‹¤íŒ¨: {fail_count} ì„¸ê·¸ë¨¼íŠ¸")
    print(f"â¡ï¸ ê±´ë„ˆë›°ê¸°: {skipped_count} ì„¸ê·¸ë¨¼íŠ¸")
    try:
        total_in_csv = len(pd.read_csv(CSV_OUTPUT_PATH))
    except:
        total_in_csv = 0
    print(f"ğŸ’¾ CSV ì´ê³„: {total_in_csv} ê°œ (VADê°€ ì°¾ì€ ì´ ìœ íš¨ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜)")
    print(f"\nğŸ“ ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜:")
    print(f"   1. CSV (í†µí•© í†µê³„): {CSV_OUTPUT_PATH}")
    print(f"   2. NPY (ì‹œê³„ì—´ numpy ë°°ì—´): {NPY_OUTPUT_DIR}")
    print(f"   3. PNG (ì˜¤ë””ì˜¤ ìŠ¤í™íŠ¸ë¡œê·¸ë¨): {AUDIO_IMG_DIR}")
    print("="*70)


if __name__ == "__main__":

    main()

