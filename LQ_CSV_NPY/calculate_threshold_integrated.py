# calculate_threshold_integrated.py
# (Integrated Model: XGBoost + Tabular AE + RNN AE ì„ê³„ê°’ ê³„ì‚°)

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import os
import xgboost as xgb
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
from tqdm import tqdm
from types import SimpleNamespace

# --- 1. ì„¤ì • ë° ê²½ë¡œ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼) ---
config = SimpleNamespace(
    batch_size = 64,
    rnn_hidden_dim = 128,
    rnn_layers = 2,
    rnn_type = "GRU",
    tab_latent_dim = 128
)

CSV_FILE_PATH = "./cleaned_statistics_all_merged.csv"
NPY_DIR = "./2_npy_timeseries"
NPY_SEQ_LENGTH = 90
NPY_FEATURES = 5

# ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
XGB_MODEL_PATH = 'best_xgb_model.joblib'
DL_MODEL_PATH = 'best_integrated_dl.pt'
TAB_SCALER_PATH = 'final_tab_scaler.joblib'
NPY_SCALER_PATH = 'final_npy_scaler.joblib'

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- 2. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ 100% ì¼ì¹˜í•´ì•¼ í•¨) ---
class TabularAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128), nn.ReLU(), nn.BatchNorm1d(128),
            nn.Linear(128, latent_dim), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128), nn.ReLU(), nn.BatchNorm1d(128),
            nn.Linear(128, input_dim)
        )
    def forward(self, x): return self.decoder(self.encoder(x))

class RNNAE(nn.Module):
    def __init__(self, rnn_type, hidden_dim, num_layers):
        super().__init__()
        self.rnn_type = rnn_type
        if rnn_type == 'LSTM':
            self.enc = nn.LSTM(NPY_FEATURES, hidden_dim, num_layers, batch_first=True)
            self.dec = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        else:
            self.enc = nn.GRU(NPY_FEATURES, hidden_dim, num_layers, batch_first=True)
            self.dec = nn.GRU(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.out = nn.Linear(hidden_dim, NPY_FEATURES)
        
    def forward(self, x):
        if self.rnn_type == 'LSTM': _, (h, _) = self.enc(x)
        else: _, h = self.enc(x)
        h_rep = h[-1].unsqueeze(1).repeat(1, NPY_SEQ_LENGTH, 1)
        dec_out, _ = self.dec(h_rep)
        return self.out(dec_out)

# --- 3. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (Validation Set ì¶”ì¶œ) ---
def load_val_data():
    print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    # 1. CSV ë° Scaler ë¡œë“œ
    if not os.path.exists(CSV_FILE_PATH): raise FileNotFoundError("CSV ì—†ìŒ")
    df = pd.read_csv(CSV_FILE_PATH)
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    num_cols = df.select_dtypes(include=[np.number]).columns
    df[num_cols] = df[num_cols].fillna(0)
    feat_cols = [c for c in num_cols if c not in ['label']] # í•™ìŠµë•Œ ì“´ ì»¬ëŸ¼ëª… ìë™ ì¶”ì¶œ
    
    # Scaler ë¡œë“œ (ì¬í•™ìŠµ ê¸ˆì§€)
    if not os.path.exists(TAB_SCALER_PATH): raise FileNotFoundError("Tabular Scaler ì—†ìŒ")
    if not os.path.exists(NPY_SCALER_PATH): raise FileNotFoundError("NPY Scaler ì—†ìŒ")
    
    tab_scaler = joblib.load(TAB_SCALER_PATH)
    npy_scaler = joblib.load(NPY_SCALER_PATH)
    
    # Tabular ë³€í™˜
    X_tab_all = tab_scaler.transform(df[feat_cols])
    
    # NPY ë¡œë“œ ë° ë³€í™˜
    X_npy_all = np.zeros((len(df), NPY_SEQ_LENGTH, NPY_FEATURES), dtype=np.float32)
    print("   - NPY íŒŒì¼ ë§¤í•‘ ì¤‘ (ì‹œê°„ ì†Œìš”)...")
    
    # ë¹ ë¥¸ ë¡œë”©ì„ ìœ„í•´ exists ì²´í¬ ìµœì†Œí™” ë° ë°°ì¹˜ ì²˜ë¦¬ ê³ ë ¤ ê°€ëŠ¥í•˜ë‚˜, 
    # ì •í™•ì„±ì„ ìœ„í•´ Loop ì‚¬ìš© (tqdm)
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        video_id = row['video_id']
        npy_path = os.path.join(NPY_DIR, f"{video_id}.npy")
        try:
            if os.path.exists(npy_path):
                d = np.load(npy_path, allow_pickle=True).item()
                m = np.stack([
                    d['mouth']['laplacian_mean'], d['mouth']['laplacian_var'],
                    d['mouth']['light_intensity_mean'], d['mouth']['light_intensity_change'],
                    d['mouth']['area']
                ], axis=1)
                
                # ê¸¸ì´ ë§ì¶¤
                curr = m.shape[0]
                if curr > NPY_SEQ_LENGTH: m = m[:NPY_SEQ_LENGTH]
                elif curr < NPY_SEQ_LENGTH: m = np.vstack([m, np.zeros((NPY_SEQ_LENGTH-curr, NPY_FEATURES))])
                
                X_npy_all[idx] = m
        except: pass # ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ìœ ì§€
        
    # NPY Scaling
    N, T, F = X_npy_all.shape
    X_npy_all = npy_scaler.transform(X_npy_all.reshape(-1, F)).reshape(N, T, F)
    
    # Train/Val Split (í•™ìŠµê³¼ ë™ì¼í•œ ì‹œë“œ 42 ì‚¬ìš© í•„ìˆ˜)
    indices = np.arange(len(df))
    # Pseudo labelì€ í•„ìš” ì—†ì§€ë§Œ split ì¬í˜„ì„ ìœ„í•´ ê·¸ëƒ¥ ëœë¤ ìŠ¤í”Œë¦¿ (stratify ì—†ì´) 
    # *ì£¼ì˜: í•™ìŠµ ì½”ë“œì—ì„  stratify=pseudo_labels ì˜€ìœ¼ë‚˜, 
    # ì—¬ê¸°ì„  ê·¸ëƒ¥ ê°™ì€ random_state=42ë©´ ëŒ€ëµì ìœ¼ë¡œ ë¶„í¬ê°€ ìœ ì§€ëœë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜,
    # ë‹¨ìˆœíˆ 8:2 ëœë¤ ìŠ¤í”Œë¦¿ì„ í•´ë„ ë¶„í¬ íŒŒì•…ì—” í° ë¬´ë¦¬ ì—†ìŒ.
    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)
    
    return {
        "tab": X_tab_all[val_idx],
        "npy": X_npy_all[val_idx],
        "input_dim": len(feat_cols)
    }

# --- 4. ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    print(f"ğŸš€ [í†µí•© ëª¨ë¸ ì„ê³„ê°’ ê³„ì‚°] ì‹œì‘ (Device: {device})")
    
    # 1. ë°ì´í„° ì¤€ë¹„
    DATA = load_val_data()
    val_tab = torch.FloatTensor(DATA['tab'])
    val_npy = torch.FloatTensor(DATA['npy'])
    
    val_ds = TensorDataset(val_tab, val_npy)
    val_loader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False)
    
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„° ê°œìˆ˜: {len(val_tab)}ê°œ")
    
    # 2. ëª¨ë¸ ë¡œë“œ
    # (1) Deep Learning Models
    print("Load Deep Learning Models...")
    checkpoint = torch.load(DL_MODEL_PATH, map_location=device)
    
    model_tab = TabularAE(DATA['input_dim'], config.tab_latent_dim).to(device)
    model_rnn = RNNAE(config.rnn_type, config.rnn_hidden_dim, config.rnn_layers).to(device)
    
    model_tab.load_state_dict(checkpoint['model_tab'])
    model_rnn.load_state_dict(checkpoint['model_rnn'])
    model_tab.eval()
    model_rnn.eval()
    
    # (2) XGBoost Model
    print("Load XGBoost Model...")
    xgb_model = joblib.load(XGB_MODEL_PATH)
    
    # 3. ìŠ¤ì½”ì–´ ê³„ì‚°
    dl_losses = []  # AE Reconstruction Error
    xgb_probs = []  # XGBoost Anomaly Probability
    
    print("ğŸ” ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
    
    # XGBoost ì˜ˆì¸¡ (CPU/GPU ìë™ ì²˜ë¦¬ë¨, ì—¬ê¸°ì„  numpy array í•„ìš”)
    # XGBoostëŠ” ë°°ì¹˜ ë‹¨ìœ„ë³´ë‹¤ ì „ì²´ë¥¼ ë„£ëŠ”ê²Œ ë¹ ë¥¼ ìˆ˜ ìˆìŒ
    xgb_preds = xgb_model.predict_proba(DATA['tab'])[:, 1] # Class 1 í™•ë¥ 
    xgb_probs.extend(xgb_preds)
    
    # DL ì˜ˆì¸¡ (Batch ë‹¨ìœ„)
    with torch.no_grad():
        for tab_x, npy_x in tqdm(val_loader):
            tab_x, npy_x = tab_x.to(device), npy_x.to(device)
            
            # Forward
            rec_tab = model_tab(tab_x)
            rec_rnn = model_rnn(npy_x) # (Batch, 5) output of last step
            
            # Loss ê³„ì‚° (Sample-wise)
            # Tabular: (B, Features) -> (B,)
            loss_tab = torch.mean((rec_tab - tab_x)**2, dim=1)
            
            # RNN: Output layer shape check needed.
            # í•™ìŠµ ì½”ë“œ RNNAE.forwardëŠ” self.out(dec_out)ì„ ë¦¬í„´í•¨. 
            # dec_out shapeì€ (B, Seq, Hidden) -> output (B, Seq, Features)
            # í•™ìŠµ ì½”ë“œì˜ LossëŠ” criterion(model_rnn(npy_x), npy_x) ì˜€ìŒ.
            
            # ë³µì› ì˜¤ì°¨ ê³„ì‚°
            loss_rnn = torch.mean((rec_rnn - npy_x)**2, dim=[1, 2])
            
            # Total DL Anomaly Score
            total_loss = loss_tab + loss_rnn
            dl_losses.extend(total_loss.cpu().numpy())

    # 4. í†µê³„ ë° ì‹œê°í™”
    dl_losses = np.array(dl_losses)
    xgb_probs = np.array(xgb_probs)
    
    # --- [ê²°ê³¼ 1] ë”¥ëŸ¬ë‹(AE) ë³µì› ì˜¤ì°¨ ë¶„ì„ ---
    mean_loss = np.mean(dl_losses)
    std_loss = np.std(dl_losses)
    max_loss = np.max(dl_losses)
    
    thresh_dl_2std = mean_loss + 2 * std_loss
    thresh_dl_3std = mean_loss + 3 * std_loss
    
    print("\n" + "="*40)
    print(f"ğŸ“Š [1. Deep Learning (AE) ë³µì› ì˜¤ì°¨ í†µê³„]")
    print(f" - í‰ê· : {mean_loss:.6f}, í‘œì¤€í¸ì°¨: {std_loss:.6f}")
    print(f" - ìµœëŒ€ê°’: {max_loss:.6f}")
    print("-" * 40)
    print(f"ğŸ’¡ ì¶”ì²œ ì„ê³„ê°’ (DL Reconstruction Error):")
    print(f"   1ï¸âƒ£ ëŠìŠ¨í•œ ê¸°ì¤€ (Mean + 2Ïƒ): {thresh_dl_2std:.6f}")
    print(f"   2ï¸âƒ£ ì—„ê²©í•œ ê¸°ì¤€ (Mean + 3Ïƒ): {thresh_dl_3std:.6f}")
    print(f"   3ï¸âƒ£ ìµœëŒ€ê°’ ê¸°ì¤€ (Max):       {max_loss:.6f}")
    print("="*40)

    # --- [ê²°ê³¼ 2] XGBoost í™•ë¥  ë¶„í¬ ë¶„ì„ ---
    mean_prob = np.mean(xgb_probs)
    max_prob = np.max(xgb_probs)
    
    print(f"\nğŸ“Š [2. XGBoost ì˜ˆì¸¡ í™•ë¥ (Class 1) í†µê³„]")
    print(f" - í‰ê·  í™•ë¥ : {mean_prob:.4f}")
    print(f" - ìµœëŒ€ í™•ë¥ : {max_prob:.4f}")
    print(f" - (ì°¸ê³ ) XGBoostëŠ” ë³´í†µ 0.5 ì´ìƒì„ ì´ìƒì¹˜(Class 1)ë¡œ ë´…ë‹ˆë‹¤.")
    
    # 5. íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸° (ë‘ ëª¨ë¸ ë”°ë¡œ)
    fig, ax = plt.subplots(1, 2, figsize=(15, 6))
    
    # DL Histogram
    sns.histplot(dl_losses, bins=50, kde=True, ax=ax[0], color='blue')
    ax[0].axvline(thresh_dl_2std, color='orange', linestyle='--', label='2 std')
    ax[0].axvline(thresh_dl_3std, color='red', linestyle='--', label='3 std')
    ax[0].set_title("DL Autoencoder Reconstruction Error")
    ax[0].set_xlabel("MSE Loss")
    ax[0].legend()
    
    # XGB Histogram
    sns.histplot(xgb_probs, bins=50, kde=True, ax=ax[1], color='green')
    ax[1].axvline(0.5, color='red', linestyle='--', label='Default Threshold (0.5)')
    ax[1].set_title("XGBoost Anomaly Probability")
    ax[1].set_xlabel("Probability (Class 1)")
    ax[1].legend()
    
    plt.tight_layout()
    plt.savefig("threshold_distribution_integrated.png")
    print(f"\nğŸ“ˆ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: threshold_distribution_integrated.png")