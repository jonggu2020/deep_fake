# calculate_threshold_engine1.py
# (Engine 1 ëª¨ë¸ë“¤ì˜ ì •ìƒ ë°ì´í„° ë¶„í¬ ë¶„ì„ ë° ìž„ê³„ê°’ ì‚°ì¶œ)

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import os
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from joblib import load, dump
from tqdm import tqdm
from torch.utils.data import TensorDataset, DataLoader

# --- 1. ì„¤ì • ë° ê²½ë¡œ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•´ì•¼ í•¨) ---
CONFIG = {
    'dl_batch_size': 256, # ì¶”ë¡ ìš©ì´ë¼ í¬ê²Œ ìž¡ì•„ë„ ë¨
    'rnn_hidden_dim': 128,
    'rnn_layers': 2,
    'rnn_type': "GRU",
    'tab_latent_dim': 64,
    'seq_len': 90,
    'n_features': 5
}

# ê²½ë¡œ (Engine 1 ì €ìž¥ ê²½ë¡œ)
MODEL_DIR = "./models/engine1"
CSV_FILE_PATH = "./master_summary_v11_cleaned_final.csv"
NPY_DIR = "./2_npy_timeseries"

# GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- 2. ëª¨ë¸ í´ëž˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ 100% ì¼ì¹˜í•´ì•¼ í•¨) ---
class TabularAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128), nn.ReLU(), nn.BatchNorm1d(128),
            nn.Linear(128, latent_dim), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128), nn.ReLU(), nn.BatchNorm1d(128),
            nn.Linear(128, input_dim)
        )
    def forward(self, x): return self.decoder(self.encoder(x))

class RNNAE(nn.Module):
    def __init__(self, rnn_type, hidden_dim, num_layers):
        super().__init__()
        self.enc = nn.GRU(CONFIG['n_features'], hidden_dim, num_layers, batch_first=True)
        self.dec = nn.GRU(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.out = nn.Linear(hidden_dim, CONFIG['n_features'])
    def forward(self, x):
        _, h = self.enc(x)
        h_rep = h[-1].unsqueeze(1).repeat(1, CONFIG['seq_len'], 1)
        dec_out, _ = self.dec(h_rep)
        return self.out(dec_out)

# --- 3. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì €ìž¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©) ---
def load_inference_data():
    print("ðŸ“¥ ë°ì´í„° ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘...")
    
    # 1. CSV ë¡œë“œ
    df = pd.read_csv(CSV_FILE_PATH)
    num_cols = df.select_dtypes(include=[np.number]).columns
    df[num_cols] = df[num_cols].fillna(0)
    feat_cols = [c for c in num_cols if c not in ['label']]
    
    # 2. ì €ìž¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    try:
        tab_scaler = load(os.path.join(MODEL_DIR, "tab_scaler.joblib"))
        npy_scaler = load(os.path.join(MODEL_DIR, "npy_scaler.joblib"))
    except FileNotFoundError:
        print("âŒ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì´ ë¨¼ì € ì™„ë£Œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        exit()
        
    # 3. Tabular ë³€í™˜
    X_tab = tab_scaler.transform(df[feat_cols])
    
    # 4. NPY ë¡œë“œ ë° ë³€í™˜
    X_npy = np.zeros((len(df), CONFIG['seq_len'], CONFIG['n_features']), dtype=np.float32)
    valid_indices = [] # NPYê°€ ì‹¤ì œë¡œ ìžˆëŠ” ì¸ë±ìŠ¤ë§Œ ì¶”ë¦¼
    
    print("ðŸ“¥ NPY ë§¤ì¹­ ë° ë³€í™˜ ì¤‘...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        try:
            path = os.path.join(NPY_DIR, f"{row['video_id']}.npy")
            if os.path.exists(path):
                d = np.load(path, allow_pickle=True).item()
                m = np.stack([
                    d['mouth']['laplacian_mean'], d['mouth']['laplacian_var'],
                    d['mouth']['light_intensity_mean'], d['mouth']['light_intensity_change'],
                    d['mouth']['area']
                ], axis=1)
                
                curr = m.shape[0]
                if curr > CONFIG['seq_len']: m = m[:CONFIG['seq_len']]
                elif curr < CONFIG['seq_len']: m = np.vstack([m, np.zeros((CONFIG['seq_len']-curr, CONFIG['n_features']))])
                
                X_npy[idx] = m
                valid_indices.append(idx)
        except: pass
    
    # NPY ìŠ¤ì¼€ì¼ë§
    N, T, F = X_npy.shape
    X_npy = npy_scaler.transform(X_npy.reshape(-1, F)).reshape(N, T, F)
    
    # NPYê°€ ìžˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§ (ë¶„ì„ ì •í™•ë„ë¥¼ ìœ„í•´)
    X_tab = X_tab[valid_indices]
    X_npy = X_npy[valid_indices]
    
    return X_tab, X_npy, len(feat_cols)

# --- 4. ë©”ì¸ ì‹¤í–‰: ìž„ê³„ê°’ ê³„ì‚° ---
if __name__ == "__main__":
    # 1. ë°ì´í„° ì¤€ë¹„
    X_tab, X_npy, tab_dim = load_inference_data()
    print(f"ðŸ“Š ë¶„ì„ ëŒ€ìƒ ë°ì´í„° ìˆ˜: {len(X_tab)}ê°œ")

    # 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    print("\nðŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # XGBoost
    xgb_model = xgb.XGBClassifier()
    xgb_model.load_model(os.path.join(MODEL_DIR, "xgb_model.json"))
    
    # Tabular AE
    model_tab = TabularAE(tab_dim, CONFIG['tab_latent_dim']).to(device)
    model_tab.load_state_dict(torch.load(os.path.join(MODEL_DIR, "tabular_ae.pth"), map_location=device))
    model_tab.eval()
    
    # RNN AE
    model_rnn = RNNAE(CONFIG['rnn_type'], CONFIG['rnn_hidden_dim'], CONFIG['rnn_layers']).to(device)
    model_rnn.load_state_dict(torch.load(os.path.join(MODEL_DIR, "rnn_ae.pth"), map_location=device))
    model_rnn.eval()
    
    # 3. ì ìˆ˜(Loss/Prob) ê³„ì‚°
    print("ðŸ” ê° ëª¨ë¸ë³„ Anomaly Score ê³„ì‚° ì¤‘...")
    
    # XGBoost Score (Probability of class 1)
    # ì£¼ì˜: í•™ìŠµ ì‹œ class 1ì„ 'ì´ìƒì¹˜(Pseudo-Anomaly)'ë¡œ ë’€ëŠ”ì§€ í™•ì¸ í•„ìš”.
    # ë³´í†µ IsolationForest -1ì„ 1ë¡œ ë’€ìœ¼ë¯€ë¡œ, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì´ìƒì¹˜.
    xgb_probs = xgb_model.predict_proba(X_tab)[:, 1] 
    
    # Deep Learning Scores
    tab_losses = []
    rnn_losses = []
    
    ds = TensorDataset(torch.FloatTensor(X_tab), torch.FloatTensor(X_npy))
    loader = DataLoader(ds, batch_size=CONFIG['dl_batch_size'], shuffle=False)
    
    criterion = nn.MSELoss(reduction='none') # ê°œë³„ ìƒ˜í”Œë³„ Loss ê³„ì‚°
    
    with torch.no_grad():
        for bx_tab, bx_npy in tqdm(loader):
            bx_tab, bx_npy = bx_tab.to(device), bx_npy.to(device)
            
            # Tabular AE Loss
            out_tab = model_tab(bx_tab)
            loss_t = torch.mean((out_tab - bx_tab)**2, dim=1) # (Batch,)
            tab_losses.extend(loss_t.cpu().numpy())
            
            # RNN AE Loss
            out_rnn = model_rnn(bx_npy)
            loss_r = torch.mean((out_rnn - bx_npy)**2, dim=[1, 2]) # (Batch,)
            rnn_losses.extend(loss_r.cpu().numpy())
            
    tab_losses = np.array(tab_losses)
    rnn_losses = np.array(rnn_losses)
    
    # 4. í†µê³„ ë° ìž„ê³„ê°’ ì œì•ˆ
    def print_stats(name, data):
        mean, std, dmax = np.mean(data), np.std(data), np.max(data)
        th_3std = mean + 3 * std
        print(f"\nðŸ“Œ [{name}] Score í†µê³„")
        print(f"   Mean: {mean:.4f} | Std: {std:.4f} | Max: {dmax:.4f}")
        print(f"   ðŸ‘‰ ì¶”ì²œ ìž„ê³„ê°’ (Mean + 3Ïƒ): {th_3std:.4f}")
        return th_3std

    print("\n" + "="*40)
    th_xgb = print_stats("XGBoost (Probability)", xgb_probs)
    th_tab = print_stats("Tabular AE (MSE)", tab_losses)
    th_rnn = print_stats("RNN AE (MSE)", rnn_losses)
    print("="*40)
    
    # 5. ìž„ê³„ê°’ ì €ìž¥
    thresholds = {
        "xgb_threshold": float(th_xgb),
        "tabular_ae_threshold": float(th_tab),
        "rnn_ae_threshold": float(th_rnn)
    }
    dump(thresholds, os.path.join(MODEL_DIR, "thresholds.joblib"))
    print(f"\nðŸ’¾ ìž„ê³„ê°’ ì„¤ì • íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {os.path.join(MODEL_DIR, 'thresholds.joblib')}")

    # 6. ížˆìŠ¤í† ê·¸ëž¨ ì‹œê°í™” ë° ì €ìž¥
    plt.figure(figsize=(18, 5))
    
    plt.subplot(1, 3, 1)
    sns.histplot(xgb_probs, bins=50, kde=True, color='blue')
    plt.axvline(th_xgb, color='red', linestyle='--', label=f'Threshold: {th_xgb:.2f}')
    plt.title("XGBoost Anomaly Probability")
    plt.legend()
    
    plt.subplot(1, 3, 2)
    sns.histplot(tab_losses, bins=50, kde=True, color='green')
    plt.axvline(th_tab, color='red', linestyle='--', label=f'Threshold: {th_tab:.2f}')
    plt.title("Tabular AE Reconstruction Error")
    plt.legend()
    
    plt.subplot(1, 3, 3)
    sns.histplot(rnn_losses, bins=50, kde=True, color='orange')
    plt.axvline(th_rnn, color='red', linestyle='--', label=f'Threshold: {th_rnn:.2f}')
    plt.title("RNN AE Reconstruction Error")
    plt.legend()
    
    save_img_path = os.path.join(MODEL_DIR, "threshold_distributions.png")
    plt.savefig(save_img_path)
    print(f"ðŸ“ˆ ë¶„í¬ ê·¸ëž˜í”„ ì €ìž¥ ì™„ë£Œ: {save_img_path}")
    # plt.show() # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ